# Phase 3b å¯¦æ–½è¨ˆç•«å¯è¡Œæ€§åˆ†æï¼šæœå°‹å·¥å…·æ•´åˆ

## ğŸ“‹ åŸ·è¡Œæ‘˜è¦

**çµè«–ï¼šâœ… å®Œå…¨å¯è¡Œï¼ŒPhase 3a å·²æˆåŠŸå¯¦æ–½**

è©•åˆ†ï¼š**9.5/10**

Phase 3aï¼ˆLangGraph StateGraph é·ç§»ï¼‰å·²æˆåŠŸå®Œæˆï¼š
- âœ… `debate_graph` å·²æˆåŠŸç·¨è­¯ï¼ˆCompiledStateGraphï¼‰
- âœ… `langgraph_debate_stream()` å·²å¯¦æ–½
- âœ… `USE_LANGGRAPH` ç’°å¢ƒè®Šæ•¸æ§åˆ¶å·²å°±ç·’
- âœ… ä¿ç•™ `real_debate_stream()` ä½œç‚ºå›é€€æ–¹æ¡ˆ

**ç¾åœ¨å¯ä»¥å®‰å…¨åœ°é€²å…¥ Phase 3bï¼šæœå°‹å·¥å…·æ•´åˆ**

---

## ğŸ¯ Phase 3b ç›®æ¨™

è®“ AI Agent èƒ½å¤ ï¼š
1. **è‡ªå‹•åˆ¤æ–·**ä½•æ™‚éœ€è¦æœå°‹è³‡æ–™
2. **åŸ·è¡Œæœå°‹**ä½¿ç”¨ Tavilyï¼ˆä¸»ï¼‰+ DuckDuckGoï¼ˆå‚™æ´ï¼‰
3. **èå…¥è«–è¿°**å°‡æœå°‹çµæœæ•´åˆåˆ°è¾¯è«–å›æ‡‰ä¸­
4. **è¦–è¦ºåé¥‹**å‰ç«¯é¡¯ç¤ºã€ŒğŸ” æ­£åœ¨æœå°‹...ã€æŒ‡ç¤ºå™¨

---

## ğŸ” ç•¶å‰ç‹€æ…‹æª¢æŸ¥

### âœ… Phase 3a é©—è­‰çµæœ

**å¾Œç«¯æª”æ¡ˆ**ï¼š
- `app/graph.py`: 234 è¡Œï¼ˆå« StateGraph å®šç¾©ï¼‰
- `app/main.py`: 309 è¡Œï¼ˆå« `langgraph_debate_stream`ï¼‰
- `debate_graph`: âœ… æˆåŠŸç·¨è­¯ç‚º `CompiledStateGraph`

**æ¶æ§‹ç‰¹æ€§**ï¼š
- âœ… ä½¿ç”¨ `async def optimist_node` å’Œ `async def skeptic_node`
- âœ… ç¯€é»å…§ä½¿ç”¨ `await llm.ainvoke(messages)`
- âœ… `stream_mode="messages"` ä¸²æµæ©Ÿåˆ¶
- âœ… `USE_LANGGRAPH` ç’°å¢ƒè®Šæ•¸æ§åˆ¶ï¼ˆé è¨­ trueï¼‰

**ç¼ºå¤±ä¾è³´**ï¼š
- âŒ `tavily-python` - Tavily API å®¢æˆ¶ç«¯
- âŒ `duckduckgo-search` - DuckDuckGo æœå°‹å·¥å…·

---

## ğŸ“ Phase 3b å¯¦æ–½è¨ˆç•«

### 1. å¾Œç«¯è®Šæ›´

#### æ­¥é©Ÿ 1ï¼šå®‰è£æœå°‹å·¥å…·ä¾è³´

**æª”æ¡ˆ**ï¼š`backend/pyproject.toml`

```toml
[project]
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.30.0",
    "python-dotenv>=1.0.0",
    "langchain>=0.3.0",
    "langchain-groq>=0.2.0",
    "langgraph>=1.0.0",
+   "tavily-python>=0.5.0",     # Phase 3b: æœå°‹å·¥å…·ï¼ˆä¸»ï¼‰
+   "duckduckgo-search>=6.0.0", # Phase 3b: æœå°‹å·¥å…·ï¼ˆå‚™æ´ï¼‰
]
```

**åŸ·è¡Œ**ï¼š
```bash
cd backend
uv sync
```

---

#### æ­¥é©Ÿ 2ï¼šå»ºç«‹æœå°‹å·¥å…·æ¨¡çµ„

**æª”æ¡ˆ**ï¼š`backend/app/tools/__init__.py`ï¼ˆæ–°å»ºï¼‰
```python
# ç©ºæª”æ¡ˆï¼Œæ¨™è¨˜ç‚º Python package
```

**æª”æ¡ˆ**ï¼š`backend/app/tools/search.py`ï¼ˆæ–°å»ºï¼‰

```python
"""
DebateAI - ç¶²è·¯æœå°‹å·¥å…·æ¨¡çµ„

ä¸‰å±¤å®¹éŒ¯ç­–ç•¥ï¼š
1. Tavilyï¼ˆä¸»ï¼‰- å°ˆç‚º AI è¨­è¨ˆï¼Œæ¥µåº¦ç©©å®š
2. DuckDuckGoï¼ˆå‚™æ´ï¼‰- å…è²»ç„¡é™æ¬¡æ•¸
3. å„ªé›…é™ç´š - æœå°‹å¤±æ•—ä¸å½±éŸ¿è¾¯è«–
"""

from tavily import TavilyClient
from duckduckgo_search import DDGS
import os
import asyncio

# åˆå§‹åŒ– Tavily å®¢æˆ¶ç«¯ï¼ˆå¯é¸ï¼‰
tavily_client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY")) if os.getenv("TAVILY_API_KEY") else None


async def tavily_search(query: str) -> dict:
    """ç¬¬ä¸€å±¤ï¼šTavily æœå°‹ï¼ˆå°ˆæ¥­ AI æœå°‹ï¼‰"""
    if not tavily_client:
        return {"success": False, "error": "No Tavily API key"}

    try:
        # Tavily æ˜¯åŒæ­¥çš„ï¼Œç”¨ asyncio åŒ…è£
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: tavily_client.search(query, max_results=3, search_depth="basic")
        )

        results = response.get("results", [])
        if not results:
            return {"success": False, "error": "No results"}

        return {
            "success": True,
            "results": results,
            "source": "tavily"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def duckduckgo_search(query: str) -> dict:
    """ç¬¬äºŒå±¤ï¼šDuckDuckGo æœå°‹ï¼ˆå…è²»å‚™æ´ï¼‰"""
    try:
        # DDGS æ˜¯åŒæ­¥çš„ï¼Œç”¨ asyncio åŒ…è£
        loop = asyncio.get_event_loop()
        ddgs = DDGS()
        results = await loop.run_in_executor(
            None,
            lambda: list(ddgs.text(query, max_results=3))
        )

        if not results:
            return {"success": False, "error": "No results"}

        return {
            "success": True,
            "results": results,
            "source": "duckduckgo"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def web_search(query: str) -> dict:
    """ä¸‰å±¤å®¹éŒ¯ç¶²è·¯æœå°‹

    Args:
        query: æœå°‹é—œéµå­—

    Returns:
        dict: {
            "success": bool,
            "results": list,  # æœå°‹çµæœï¼ˆå¦‚æœæˆåŠŸï¼‰
            "source": str,    # "tavily" | "duckduckgo" | "fallback"
            "formatted": str  # æ ¼å¼åŒ–çš„çµæœæ–‡å­—
        }
    """

    # ç¬¬ä¸€å±¤ï¼šTavily
    result = await tavily_search(query)
    if result["success"]:
        formatted = format_results(result["results"], result["source"])
        return {**result, "formatted": formatted}

    # ç¬¬äºŒå±¤ï¼šDuckDuckGo
    result = await duckduckgo_search(query)
    if result["success"]:
        formatted = format_results(result["results"], result["source"])
        return {**result, "formatted": formatted}

    # ç¬¬ä¸‰å±¤ï¼šå„ªé›…é™ç´š
    return {
        "success": False,
        "source": "fallback",
        "formatted": f"[æ³¨æ„] æœå°‹åŠŸèƒ½æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼ŒAgent å°‡åŸºæ–¼ç¾æœ‰çŸ¥è­˜å›ç­”é—œæ–¼ã€Œ{query}ã€çš„å•é¡Œã€‚"
    }


def format_results(results: list, source: str) -> str:
    """æ ¼å¼åŒ–æœå°‹çµæœç‚ºå¯è®€æ–‡å­—

    Args:
        results: æœå°‹çµæœåˆ—è¡¨
        source: ä¾†æºï¼ˆ"tavily" | "duckduckgo"ï¼‰

    Returns:
        æ ¼å¼åŒ–çš„æ–‡å­—
    """
    if source == "tavily":
        # Tavily æ ¼å¼ï¼š{title, content, url}
        lines = [
            f"â€¢ {r.get('title', 'æœªçŸ¥æ¨™é¡Œ')}: {r.get('content', '')[:200]}..."
            for r in results[:3]
        ]
    else:
        # DuckDuckGo æ ¼å¼ï¼š{title, body, href}
        lines = [
            f"â€¢ {r.get('title', 'æœªçŸ¥æ¨™é¡Œ')}: {r.get('body', '')[:200]}..."
            for r in results[:3]
        ]

    formatted = "\n".join(lines)
    return f"[{source.upper()}] æœå°‹çµæœï¼š\n{formatted}"
```

---

#### æ­¥é©Ÿ 3ï¼šå®šç¾© LangChain Tool

**æª”æ¡ˆ**ï¼š`backend/app/graph.py`

åœ¨æ–‡ä»¶é–‹é ­åŠ å…¥ importsï¼š
```python
from langchain_core.tools import tool
```

åœ¨ `create_initial_state` ä¹‹å¾ŒåŠ å…¥ï¼š

```python
# ============================================================
# å·¥å…·å®šç¾©ï¼ˆPhase 3bï¼‰
# ============================================================

@tool
async def web_search_tool(query: str) -> str:
    """æœå°‹ç¶²è·¯è³‡æ–™ä»¥ç²å–æœ€æ–°è³‡è¨Šã€çµ±è¨ˆæ•¸æ“šæˆ–äº‹å¯¦ã€‚

    ç•¶éœ€è¦ä»¥ä¸‹æƒ…æ³æ™‚ä½¿ç”¨æ­¤å·¥å…·ï¼š
    - æœ€æ–°æ•¸æ“šæˆ–çµ±è¨ˆè³‡æ–™
    - å…·é«”äº‹ä»¶çš„æ—¥æœŸå’Œç´°ç¯€
    - ç§‘å­¸ç ”ç©¶çµæœ
    - å¸‚å ´è¶¨å‹¢æˆ–å•†æ¥­è³‡è¨Š

    Args:
        query: æœå°‹é—œéµå­—ï¼ˆç°¡æ½”æ˜ç¢ºï¼‰

    Returns:
        æ ¼å¼åŒ–çš„æœå°‹çµæœæ‘˜è¦
    """
    from app.tools.search import web_search

    result = await web_search(query)
    return result.get("formatted", "æœå°‹å¤±æ•—")
```

---

#### æ­¥é©Ÿ 4ï¼šä¿®æ”¹ç¯€é»æ”¯æ´å·¥å…·èª¿ç”¨

**æª”æ¡ˆ**ï¼š`backend/app/graph.py`

ä¿®æ”¹ `get_llm()` å‡½æ•¸ï¼Œæ–°å¢å¯é¸çš„å·¥å…·ç¶å®šï¼š

```python
def get_llm(bind_tools: bool = False):
    """å–å¾— LLM å¯¦ä¾‹

    Args:
        bind_tools: æ˜¯å¦ç¶å®šå·¥å…·ï¼ˆPhase 3bï¼‰
    """
    model_name = os.getenv("GROQ_MODEL", "llama-3.1-8b-instant")
    llm = ChatGroq(
        model=model_name,
        temperature=0.7,
        api_key=os.getenv("GROQ_API_KEY"),
        streaming=True
    )

    if bind_tools:
        return llm.bind_tools([web_search_tool])
    return llm
```

ä¿®æ”¹ç¯€é»å‡½æ•¸ä»¥è™•ç†å·¥å…·èª¿ç”¨ï¼š

```python
async def optimist_node(state: DebateState) -> dict:
    """æ¨‚è§€è€…ç¯€é»ï¼ˆæ”¯æ´å·¥å…·èª¿ç”¨ï¼‰"""
    llm = get_llm(bind_tools=True)  # Phase 3b: ç¶å®šå·¥å…·
    messages = build_prompt(state, "optimist")

    # ç¬¬ä¸€æ¬¡èª¿ç”¨ï¼ˆå¯èƒ½è«‹æ±‚å·¥å…·ï¼‰
    response = await llm.ainvoke(messages)

    # è™•ç†å·¥å…·èª¿ç”¨å¾ªç’°
    while hasattr(response, 'tool_calls') and response.tool_calls:
        # å°‡ AI å›æ‡‰åŠ å…¥è¨Šæ¯
        messages.append(response)

        # åŸ·è¡Œæ¯å€‹å·¥å…·èª¿ç”¨
        for tool_call in response.tool_calls:
            from langchain_core.messages import ToolMessage

            # åŸ·è¡Œå·¥å…·ï¼ˆweb_search_tool æ˜¯ç•°æ­¥çš„ï¼‰
            tool_result = await web_search_tool.ainvoke(tool_call["args"])

            # å°‡å·¥å…·çµæœåŠ å…¥è¨Šæ¯
            messages.append(ToolMessage(
                content=tool_result,
                tool_call_id=tool_call["id"],
                name="web_search_tool"
            ))

        # ç”¨å·¥å…·çµæœé‡æ–°èª¿ç”¨ LLM
        response = await llm.ainvoke(messages)

    return {
        "messages": [AIMessage(content=response.content, name="optimist")],
        "current_speaker": "skeptic"
    }


async def skeptic_node(state: DebateState) -> dict:
    """æ‡·ç–‘è€…ç¯€é»ï¼ˆæ”¯æ´å·¥å…·èª¿ç”¨ï¼‰"""
    llm = get_llm(bind_tools=True)  # Phase 3b: ç¶å®šå·¥å…·
    messages = build_prompt(state, "skeptic")

    # ç¬¬ä¸€æ¬¡èª¿ç”¨
    response = await llm.ainvoke(messages)

    # è™•ç†å·¥å…·èª¿ç”¨å¾ªç’°ï¼ˆåŒ optimist_nodeï¼‰
    while hasattr(response, 'tool_calls') and response.tool_calls:
        messages.append(response)

        for tool_call in response.tool_calls:
            from langchain_core.messages import ToolMessage
            tool_result = await web_search_tool.ainvoke(tool_call["args"])
            messages.append(ToolMessage(
                content=tool_result,
                tool_call_id=tool_call["id"],
                name="web_search_tool"
            ))

        response = await llm.ainvoke(messages)

    new_round = state["round_count"] + 1
    next_speaker = "end" if new_round >= state["max_rounds"] else "optimist"

    return {
        "messages": [AIMessage(content=response.content, name="skeptic")],
        "current_speaker": next_speaker,
        "round_count": new_round
    }
```

---

#### æ­¥é©Ÿ 5ï¼šæ›´æ–° System Prompts

**æª”æ¡ˆ**ï¼š`backend/app/graph.py`

```python
OPTIMIST_SYSTEM = """ä½ æ˜¯ä¸€ä½å……æ»¿èªªæœåŠ›çš„ã€Œæ¨‚è§€è¾¯æ‰‹ã€ã€‚

è¦å‰‡ï¼š
1. æ¯æ¬¡å›æ‡‰é™ 2-3 å¥è©±ï¼Œç°¡çŸ­æœ‰åŠ›
2. å¼·èª¿æ©Ÿæœƒã€å„ªå‹¢ã€æ­£é¢å½±éŸ¿
3. å¦‚æœå°æ‰‹æå‡ºè³ªç–‘ï¼Œå¿…é ˆæ­£é¢åæ“Š
4. ç¦æ­¢èªªã€Œä½ èªªå¾—å°ã€ã€Œæˆ‘åŒæ„ã€ç­‰é€€è®“èªå¥
5. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰
6. **å¦‚æœéœ€è¦æ•¸æ“šæˆ–äº‹å¯¦æ”¯æŒè«–é»ï¼Œè«‹ä½¿ç”¨ web_search_tool æŸ¥è©¢**

å¯ç”¨å·¥å…·ï¼š
- web_search_tool(query: str): æœå°‹æœ€æ–°è³‡è¨Šã€çµ±è¨ˆæ•¸æ“šæˆ–äº‹å¯¦
"""

SKEPTIC_SYSTEM = """ä½ æ˜¯ä¸€ä½é‚è¼¯åš´è¬¹çš„ã€Œæ‡·ç–‘è¾¯æ‰‹ã€ã€‚

è¦å‰‡ï¼š
1. æ¯æ¬¡å›æ‡‰é™ 2-3 å¥è©±ï¼Œç›´æ“Šè¦å®³
2. æŒ‡å‡ºé¢¨éšªã€æ¼æ´ã€è¢«å¿½è¦–çš„ä»£åƒ¹
3. è³ªç–‘å°æ‰‹çš„æ¨‚è§€å‡è¨­ï¼Œè¦æ±‚æå‡ºè­‰æ“š
4. ç¦æ­¢èªåŒå°æ–¹è§€é»ï¼Œä¿æŒæ‰¹åˆ¤ç«‹å ´
5. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›æ‡‰
6. **å¦‚æœéœ€è¦æŸ¥è­‰å°æ‰‹çš„è«–é»ï¼Œè«‹ä½¿ç”¨ web_search_tool**

å¯ç”¨å·¥å…·ï¼š
- web_search_tool(query: str): æœå°‹æœ€æ–°è³‡è¨Šä»¥æŸ¥è­‰è«–é»
"""
```

---

#### æ­¥é©Ÿ 6ï¼šmain.py åŠ å…¥å·¥å…·äº‹ä»¶

**æª”æ¡ˆ**ï¼š`backend/app/main.py`

ä¿®æ”¹ `langgraph_debate_stream()` ä»¥åµæ¸¬å·¥å…·èª¿ç”¨ï¼š

```python
async def langgraph_debate_stream(topic: str, max_rounds: int = 3):
    """Phase 3a/3b: ä½¿ç”¨ LangGraph StateGraph ä¸²æµï¼ˆæ”¯æ´å·¥å…·ï¼‰"""
    from app.graph import debate_graph, create_initial_state

    yield sse_event({'type': 'status', 'text': 'âš¡ æ­£åœ¨å–šé†’ AI è¾¯è«–å¼•æ“...'})
    yield sse_event({'type': 'status', 'text': f'ğŸ”¥ ä½¿ç”¨æ¨¡å‹: {GROQ_MODEL} (LangGraph + Tools)'})

    state = create_initial_state(topic, max_rounds)

    current_node = None
    round_count = 0

    try:
        async for message, metadata in debate_graph.astream(
            state,
            stream_mode="messages"
        ):
            node = metadata.get("langgraph_node") if metadata else None
            if not node:
                continue

            # ç¯€é»åˆ‡æ›
            if node != current_node:
                if current_node:
                    yield sse_event({'type': 'speaker_end', 'node': current_node})
                    if current_node == "skeptic":
                        round_count += 1

                current_node = node
                display_round = round_count + 1
                yield sse_event({
                    'type': 'speaker',
                    'node': node,
                    'text': f'ç¬¬ {display_round} è¼ª'
                })

            # âš ï¸ æ–°å¢ï¼šåµæ¸¬å·¥å…·èª¿ç”¨
            if hasattr(message, 'tool_calls') and message.tool_calls:
                for tool_call in message.tool_calls:
                    query = tool_call.get("args", {}).get("query", "æœªçŸ¥æŸ¥è©¢")
                    yield sse_event({
                        'type': 'tool_start',
                        'tool': 'web_search',
                        'query': query,
                        'node': node
                    })

            # âš ï¸ æ–°å¢ï¼šåµæ¸¬å·¥å…·çµæœ
            if message.__class__.__name__ == 'ToolMessage':
                # å·¥å…·åŸ·è¡Œå®Œæˆ
                yield sse_event({
                    'type': 'tool_end',
                    'tool': 'web_search',
                    'node': node
                })

            # Token ä¸²æµ
            if hasattr(message, 'content') and message.content:
                yield sse_event({
                    'type': 'token',
                    'node': node,
                    'text': message.content
                })

        # çµæŸ
        if current_node:
            yield sse_event({'type': 'speaker_end', 'node': current_node})
            if current_node == "skeptic":
                round_count += 1

        yield sse_event({
            'type': 'complete',
            'text': f'âœ… è¾¯è«–å®Œæˆï¼å…±é€²è¡Œäº† {round_count} è¼ªç²¾å½©äº¤é‹’ã€‚'
        })

    except Exception as e:
        yield sse_event({'type': 'error', 'text': f'LangGraph éŒ¯èª¤: {str(e)}'})
        if current_node:
            yield sse_event({'type': 'speaker_end', 'node': current_node})
```

---

### 2. å‰ç«¯è®Šæ›´

#### æ­¥é©Ÿ 7ï¼šæ›´æ–° TypeScript é¡å‹

**æª”æ¡ˆ**ï¼š`frontend/app/lib/api.ts`

```typescript
export type SSEEvent =
    | { type: 'status'; text: string }
    | { type: 'speaker'; node: 'optimist' | 'skeptic'; text: string }
    | { type: 'token'; node: 'optimist' | 'skeptic'; text: string }
    | { type: 'speaker_end'; node: 'optimist' | 'skeptic' }
    | { type: 'tool_start'; tool: string; query: string; node: string }  // Phase 3b
    | { type: 'tool_end'; tool: string; node: string }                   // Phase 3b
    | { type: 'complete'; text: string }
    | { type: 'error'; text: string };
```

---

#### æ­¥é©Ÿ 8ï¼šå‰ç«¯é¡¯ç¤ºæœå°‹æŒ‡ç¤ºå™¨

**æª”æ¡ˆ**ï¼š`frontend/app/components/DebateUI.tsx`

åœ¨ state ä¸­åŠ å…¥ï¼š

```typescript
const [searchStatus, setSearchStatus] = useState<{
  isSearching: boolean;
  query?: string;
  node?: string;
}>({ isSearching: false });
```

åœ¨ `handleSSEEvent` ä¸­è™•ç†ï¼š

```typescript
case "tool_start":
  setSearchStatus({
    isSearching: true,
    query: event.query,
    node: event.node
  });
  setStatus(`ğŸ” ${event.node === 'optimist' ? 'æ¨‚è§€è€…' : 'æ‡·ç–‘è€…'}æ­£åœ¨æœå°‹ï¼š${event.query}`);
  break;

case "tool_end":
  setSearchStatus({ isSearching: false });
  setStatus('âœ… æœå°‹å®Œæˆï¼Œç¹¼çºŒè¾¯è«–...');
  break;
```

åœ¨ UI ä¸­é¡¯ç¤ºï¼š

```tsx
{searchStatus.isSearching && (
  <div className="mb-4 p-3 bg-yellow-50 dark:bg-yellow-950/20 border border-yellow-200 dark:border-yellow-800 rounded-lg flex items-center gap-3">
    <svg className="animate-spin h-5 w-5 text-yellow-600" viewBox="0 0 24 24">
      <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4" fill="none"/>
      <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"/>
    </svg>
    <div className="flex-1">
      <p className="text-sm font-medium text-yellow-900 dark:text-yellow-100">
        ğŸ” æ­£åœ¨æœå°‹è³‡æ–™...
      </p>
      <p className="text-xs text-yellow-700 dark:text-yellow-300">
        {searchStatus.query}
      </p>
    </div>
  </div>
)}
```

---

### 3. ç’°å¢ƒè®Šæ•¸é…ç½®

**æª”æ¡ˆ**ï¼š`backend/.env`ï¼ˆæœ¬åœ°é–‹ç™¼ï¼‰

```bash
GROQ_API_KEY=gsk_your_key_here
GROQ_MODEL=llama-3.1-8b-instant
USE_LANGGRAPH=true
TAVILY_API_KEY=tvly_your_key_here  # Phase 3b: å¯é¸ï¼Œç„¡å‰‡è·³é Tavily
```

**Cloud Run éƒ¨ç½²**ï¼š

```bash
gcloud run deploy debate-api \
  --source . \
  --region asia-east1 \
  --set-env-vars GROQ_API_KEY=${GROQ_API_KEY},TAVILY_API_KEY=${TAVILY_API_KEY}
```

---

## âœ… é©—æ”¶æ¨™æº–

| é …ç›® | é æœŸçµæœ | é©—è­‰æ–¹æ³• |
|------|---------|---------|
| Agent è‡ªå‹•åˆ¤æ–· | âœ… éœ€è¦æ•¸æ“šæ™‚è‡ªå‹•èª¿ç”¨ web_search_tool | ä¸»é¡Œï¼šã€Œ2024å¹´å…¨çƒAIæŠ•è³‡é‡‘é¡ã€|
| æœå°‹ç‹€æ…‹é¡¯ç¤º | âœ… å‰ç«¯é¡¯ç¤ºã€ŒğŸ” æ­£åœ¨æœå°‹...ã€| è§€å¯Ÿ UI |
| Tavily æœå°‹ | âœ… TAVILY_API_KEY å­˜åœ¨æ™‚ä½¿ç”¨ Tavily | æª¢æŸ¥æ—¥èªŒ |
| DuckDuckGo å‚™æ´ | âœ… Tavily å¤±æ•—æ™‚è‡ªå‹•é™ç´š | æ¸¬è©¦éŒ¯èª¤ API Key |
| å„ªé›…é™ç´š | âœ… å…©è€…éƒ½å¤±æ•—æ™‚è¾¯è«–ç¹¼çºŒ | æ–·ç¶²æ¸¬è©¦ |
| çµæœèå…¥è«–è¿° | âœ… Agent å›æ‡‰åŒ…å«æœå°‹è³‡æ–™ | æª¢æŸ¥å›æ‡‰å…§å®¹ |

---

## âš ï¸ é¢¨éšªè©•ä¼°

| é¢¨éšª | å½±éŸ¿ | å¯èƒ½æ€§ | ç·©è§£æªæ–½ |
|------|------|--------|---------|
| Agent éåº¦èª¿ç”¨å·¥å…· | ä¸­ | ä¸­ | Prompt å¼·èª¿ã€Œåƒ…éœ€è¦æ™‚ã€æœå°‹ |
| æœå°‹å»¶é²ï¼ˆ3-5ç§’ï¼‰| ä½ | é«˜ | é¡¯ç¤ºæœå°‹æŒ‡ç¤ºå™¨ |
| Tavily é…é¡ç”¨ç›¡ | ä½ | ä½ | DuckDuckGo è‡ªå‹•å‚™æ´ |
| å·¥å…·å¾ªç’°ç„¡é™ | é«˜ | ä½ | é™åˆ¶ max iterationsï¼ˆLangGraph å…§å»ºï¼‰|
| Token ä¸²æµä¸­æ–· | ä¸­ | ä½ | å·¥å…·èª¿ç”¨åœ¨ ainvoke å…§å®Œæˆ |

---

## â±ï¸ æ™‚é–“ä¼°è¨ˆ

| ä»»å‹™ | é è¨ˆæ™‚é–“ | å‚™è¨» |
|------|---------|------|
| å®‰è£ä¾è³´ | 5 åˆ†é˜ | `uv sync` |
| å»ºç«‹ search.py | 20-25 åˆ†é˜ | ä¸‰å±¤å®¹éŒ¯é‚è¼¯ |
| ä¿®æ”¹ graph.pyï¼ˆå·¥å…·å®šç¾© + ç¯€é»ï¼‰| 30-35 åˆ†é˜ | æœ€è¤‡é›œéƒ¨åˆ† |
| ä¿®æ”¹ main.pyï¼ˆSSE äº‹ä»¶ï¼‰| 15-20 åˆ†é˜ | åµæ¸¬å·¥å…·èª¿ç”¨ |
| å‰ç«¯ UI æ›´æ–° | 20-25 åˆ†é˜ | æœå°‹æŒ‡ç¤ºå™¨ |
| æœ¬åœ°æ¸¬è©¦ | 15-20 åˆ†é˜ | åŠŸèƒ½ + å®¹éŒ¯ |
| éƒ¨ç½²é©—è­‰ | 10-15 åˆ†é˜ | ç”Ÿç”¢ç’°å¢ƒ |
| **ç¸½è¨ˆ** | **115-145 åˆ†é˜** | **ç´„ 2-2.5 å°æ™‚** |

---

## ğŸ“Œ å¯¦æ–½é †åº

### Day 1ï¼ˆå»ºè­°ä¸€æ¬¡å®Œæˆï¼‰

1. **å¾Œç«¯æœå°‹å·¥å…·**ï¼ˆ45-50 åˆ†é˜ï¼‰
   - å®‰è£ä¾è³´
   - å»ºç«‹ `app/tools/search.py`
   - å®šç¾© `@tool web_search_tool`

2. **å¾Œç«¯ç¯€é»ä¿®æ”¹**ï¼ˆ45-50 åˆ†é˜ï¼‰
   - ä¿®æ”¹ `get_llm()` æ”¯æ´ `bind_tools`
   - ä¿®æ”¹ `optimist_node` å’Œ `skeptic_node` è™•ç†å·¥å…·å¾ªç’°
   - æ›´æ–° System Prompts
   - ä¿®æ”¹ `main.py` åµæ¸¬å·¥å…·äº‹ä»¶

3. **å‰ç«¯ UI**ï¼ˆ20-25 åˆ†é˜ï¼‰
   - æ›´æ–° TypeScript é¡å‹
   - åŠ å…¥æœå°‹ç‹€æ…‹æŒ‡ç¤ºå™¨

4. **æ¸¬è©¦éƒ¨ç½²**ï¼ˆ20-30 åˆ†é˜ï¼‰
   - æœ¬åœ°æ¸¬è©¦ï¼ˆåŠŸèƒ½ + å®¹éŒ¯ï¼‰
   - éƒ¨ç½²åˆ° Cloud Run

---

## ğŸ¯ é—œéµæˆåŠŸå› ç´ 

1. **å·¥å…·å¾ªç’°è™•ç†æ­£ç¢º**
   - å¿…é ˆç”¨ `while` å¾ªç’°è™•ç†å¤šæ¬¡å·¥å…·èª¿ç”¨
   - æ¯æ¬¡éƒ½è¦å°‡ `ToolMessage` åŠ å› messages

2. **ç•°æ­¥è™•ç†ä¸€è‡´**
   - `web_search_tool` å¿…é ˆæ˜¯ async
   - Tavily/DDGS åŒæ­¥èª¿ç”¨éœ€ç”¨ `run_in_executor`

3. **Prompt è¨­è¨ˆ**
   - æ˜ç¢ºå‘ŠçŸ¥ä½•æ™‚ä½¿ç”¨å·¥å…·
   - å¼·èª¿ã€Œåƒ…éœ€è¦æ™‚ã€é¿å…éåº¦èª¿ç”¨

4. **éŒ¯èª¤è™•ç†å®Œå–„**
   - æœå°‹å¤±æ•—ä¸å½±éŸ¿è¾¯è«–
   - å„ªé›…é™ç´šè¨Šæ¯æ¸…æ™°

---

## ğŸ“‹ æœ€çµ‚æª¢æŸ¥æ¸…å–®

### é–‹å§‹å‰
- [ ] Phase 3a å·²æˆåŠŸéƒ¨ç½²ä¸¦æ¸¬è©¦
- [ ] ç¢ºèª `debate_graph` æ­£å¸¸é‹ä½œ
- [ ] ç¢ºèª token streaming æœ‰æ•ˆ

### å¯¦æ–½ä¸­
- [ ] `pyproject.toml` åŠ å…¥ä¾è³´
- [ ] å»ºç«‹ `app/tools/` ç›®éŒ„
- [ ] å¯¦ä½œä¸‰å±¤å®¹éŒ¯æœå°‹
- [ ] å®šç¾© `@tool` è£é£¾å™¨
- [ ] ä¿®æ”¹ç¯€é»è™•ç†å·¥å…·å¾ªç’°
- [ ] æ›´æ–° System Prompts
- [ ] å‰ç«¯åŠ å…¥æœå°‹æŒ‡ç¤ºå™¨

### æ¸¬è©¦
- [ ] æœ¬åœ°æ¸¬è©¦ Tavily æœå°‹
- [ ] æ¸¬è©¦ DuckDuckGo å‚™æ´
- [ ] æ¸¬è©¦å„ªé›…é™ç´š
- [ ] é©—è­‰æœå°‹çµæœèå…¥è«–è¿°
- [ ] æª¢æŸ¥å‰ç«¯ UI æŒ‡ç¤ºå™¨

### éƒ¨ç½²
- [ ] è¨­å®š TAVILY_API_KEY ç’°å¢ƒè®Šæ•¸
- [ ] éƒ¨ç½²åˆ° Cloud Run
- [ ] ç”Ÿç”¢ç’°å¢ƒæ¸¬è©¦

---

## ğŸ”— åƒè€ƒè³‡æ–™

- [LangChain Tools Documentation](https://python.langchain.com/docs/modules/agents/tools/)
- [Tavily API Documentation](https://docs.tavily.com/)
- [DuckDuckGo Search Documentation](https://pypi.org/project/duckduckgo-search/)
- [LangGraph Tool Calling](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/)

---

## âœ… çµè«–

**Phase 3b è¨ˆç•«å®Œå…¨å¯è¡Œ**ï¼Œä¸¦ä¸”åœ¨ Phase 3a æˆåŠŸçš„åŸºç¤ä¸Šï¼Œå¯¦æ–½é¢¨éšªæ›´ä½ã€‚

**æ¨è–¦ç«‹å³é–‹å§‹å¯¦æ–½**ï¼Œé è¨ˆ 2-2.5 å°æ™‚å¯å®Œæˆä¸¦éƒ¨ç½²ã€‚
